{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se irán generando distintos features que luego deberán ser probados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id'] = df['id'].astype(np.uint16)\n",
    "df['target'] = df['target'].astype(np.uint8)\n",
    "df = df.fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features a partir de la keyword "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding de las keywords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_keyword = pd.get_dummies(df[\"keyword\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevas_col = pd.Series()\n",
    "for col in ohe_keyword.columns:\n",
    "    nuevas_col = nuevas_col.append(pd.Series(\"ohe_keyword_\" + col))\n",
    "ohe_keyword.columns = nuevas_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(objs=[df, ohe_keyword], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Encoding de las keywords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = df[\"keyword\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"keyword_count\"] = df[\"keyword\"].transform(lambda x: keywords[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versión normalizada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"keyword_count_norm\"] = df[\"keyword_count\"]/keywords.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Encoding de las keywords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_target = df.groupby([\"keyword\", \"target\"]).count()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_mean(x):\n",
    "    try:\n",
    "        targets = keywords_target[x]\n",
    "    except KeyError:\n",
    "        return 0.5\n",
    "    if len(targets) == 2:\n",
    "        return targets[0]/(targets[0]+targets[1])\n",
    "    else:\n",
    "        try:\n",
    "            return targets[0]/targets[0]\n",
    "        except KeyError:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"keyword_mean\"] = df[\"keyword\"].transform(keyword_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature que indica si la keyword está o no en el tweet: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"keyword_en_tweet\"] = df.agg(lambda x: 1 if x[\"keyword\"].lower() in x[\"text\"].lower().split() else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features a partir de la location "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding de las location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_location = pd.get_dummies(df[\"location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevas_col = pd.Series()\n",
    "for col in ohe_location.columns:\n",
    "    nuevas_col = nuevas_col.append(pd.Series(\"ohe_location_\" + col))\n",
    "ohe_location.columns = nuevas_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(objs=[df, ohe_location], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Encoding de las location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = df[\"location\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"location_count\"] = df[\"location\"].transform(lambda x: locations[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versión normalizada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"location_count_norm\"] = df[\"location_count\"]/locations.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Encoding de las location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_target = df.groupby([\"location\", \"target\"]).count()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_mean(x):\n",
    "    try:\n",
    "        targets = locations_target[x]\n",
    "    except KeyError:\n",
    "        return 0.5\n",
    "    if len(targets) == 2:\n",
    "        return targets[0]/(targets[0]+targets[1])\n",
    "    else:\n",
    "        try:\n",
    "            return targets[0]/targets[0]\n",
    "        except KeyError:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"location_mean\"] = df[\"location\"].transform(location_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features a partir del tweet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature que indica la longitud del tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"long\"] = df[\"text\"].transform(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versión normalizada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"long_norm\"] = df[\"long\"]/df[\"long\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature que indica la cantidad de términos en el tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"nro_term\"] = df[\"text\"].transform(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versión normalizada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"nro_term_norm\"] = df[\"nro_term\"]/df[\"nro_term\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature que indica si el tweet contiene una URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hay_url(x):\n",
    "    if re.search('https{0,1}:\\/\\/\\S*', x) is not None:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df[\"hay_url\"] = df[\"text\"].transform(hay_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature que indica si en el tweet hay algún número o no:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hay_nros(x):\n",
    "    x = x.split()\n",
    "    for i in x:\n",
    "        i = i.replace(',','')\n",
    "        try:\n",
    "            float(i)\n",
    "            return 1\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return 0 \n",
    "\n",
    "df[\"hay_nros\"] = df[\"text\"].transform(hay_nros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature que indica si el tweet contiene una mención:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hay_mencion(x):\n",
    "    for i in x.split():\n",
    "        if i[0]=='@':\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "df[\"hay_mencion\"] = df[\"text\"].transform(hay_mencion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature que indica si el tweet contiene un hashtag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hay_hashtag(x):\n",
    "    for i in x.split():\n",
    "        if i[0]=='#':\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "df[\"hay_hashtag\"] = df[\"text\"].transform(hay_hashtag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para limpiar el texto de los mensajes.\n",
    "def clean_text(text):\n",
    "    # Se convierte el texto a minúsculas.\n",
    "    text = text.lower()\n",
    "    # Se quitan los '#'.\n",
    "    text = re.sub('#', '', text)\n",
    "    # Se quitan los números.\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    # Se quitan los saltos de línea.\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    # Se eliminan las referencias a usuarios '@user'.\n",
    "    text = re.sub('@\\S*', '', text)\n",
    "    # Se quitan vínculos URL.\n",
    "    text = re.sub('https{0,1}:\\/\\/\\S*', ' ', text)\n",
    "    # Se simplifican múltiples espacios a uno solo.\n",
    "    text = re.sub('(\\ ){2,7}', ' ',text)\n",
    "    # Se quitan los signos de puntuación.\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vect = CountVectorizer(stop_words='english', preprocessor=clean_text, max_df=0.5, min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_cols = pd.DataFrame(c_vect.fit_transform(df[\"text\"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevas_col = pd.Series()\n",
    "for col in bow_cols.columns:\n",
    "    nuevas_col = nuevas_col.append(pd.Series(\"bow_\" + str(col)))\n",
    "bow_cols.columns = nuevas_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(objs=[df, bow_cols], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Hashing de 101 columnas para el tweet con modelo BOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_vect = HashingVectorizer(stop_words='english', preprocessor=clean_text, n_features=101, norm=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh_cols = pd.DataFrame(h_vect.fit_transform(df[\"text\"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevas_col = pd.Series()\n",
    "for col in fh_cols.columns:\n",
    "    nuevas_col = nuevas_col.append(pd.Series(\"fh101_\" + str(col)))\n",
    "fh_cols.columns = nuevas_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(objs=[df, fh_cols], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words='english', preprocessor=clean_text, max_df=0.5, min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_cols = pd.DataFrame(tfidf_vect.fit_transform(df[\"text\"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevas_col = pd.Series()\n",
    "for col in tfidf_cols.columns:\n",
    "    nuevas_col = nuevas_col.append(pd.Series(\"tfidf_\" + str(col)))\n",
    "tfidf_cols.columns = nuevas_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(objs=[df, tfidf_cols], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Hashing de 1001 columnas para el tweet con modelo BOW con trigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_vect_3g = HashingVectorizer(stop_words='english', preprocessor=clean_text, ngram_range=(1,3), n_features=1001, norm=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh3g_cols = pd.DataFrame(h_vect_3g.fit_transform(df[\"text\"]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevas_col = pd.Series()\n",
    "for col in fh3g_cols.columns:\n",
    "    nuevas_col = nuevas_col.append(pd.Series(\"fh3g1001_\" + str(col)))\n",
    "fh3g_cols.columns = nuevas_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(objs=[df, fh3g_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"train_proc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
